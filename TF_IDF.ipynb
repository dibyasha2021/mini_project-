{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF-IDF.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNaCba9Zu1r6KqN2Go21s7k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dibyasha2021/mini_project-/blob/main/TF_IDF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lZVznlgAA0_7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebc1f340-e613-474f-b652-fd87a6a61bbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "#importing Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import math\n",
        "from nltk.tokenize import RegexpTokenizer,sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "import nltk\n",
        "\n",
        "#nltk.download('all')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Doc1=\"Python is a computer programming language often used to build websites and software, automate tasks, and conduct data analysis.\"\n",
        "Doc2=\" Python is a general-purpose language, meaning it can be used to create a variety of different programs and is not specialized for any specific problems.\"\n",
        "Doc3=\"Python is an extremely popular programming language that is officially employed as the primary programming language by the great majority of enterprises.\"\n",
        "Doc4=\" This versatility, along with its beginner-friendliness, has made it one of the most-used programming languages today.\"\n",
        "Doc5=\"A survey conducted by industry analyst firm RedMonk found that it was the second-most popular programming language among developers in 2021.\"\n"
      ],
      "metadata": {
        "id": "pANQj4FEA7mc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AllDoc=[Doc1,Doc2,Doc3,Doc4,Doc5]\n",
        "#AllDoc"
      ],
      "metadata": {
        "id": "ecvvjP7PiU4k"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list of Doc after removing stopwods\n",
        "New_alldoc=[]\n",
        "for doc in AllDoc:\n",
        "  New_alldoc.append(remove_stopwords(doc))\n",
        "print(New_alldoc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LHwi4fvfJ4R",
        "outputId": "9ccc2fb5-bc38-4de3-e411-897599923be6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Python programming language build websites software, automate tasks, conduct data analysis.', 'Python general-purpose language, meaning create variety different programs specialized specific problems.', 'Python extremely popular programming language officially employed primary programming language great majority enterprises.', 'This versatility, beginner-friendliness, most-used programming languages today.', 'A survey conducted industry analyst firm RedMonk second-most popular programming language developers 2021.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenization and lemmetization\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "Documents=[]\n",
        "for doc in New_alldoc:\n",
        "    sentence=\" \".join(re.split(r'[-\\s.,;!?]+',doc))\n",
        "    tokens=word_tokenize(sentence)\n",
        "    text=[]\n",
        "    for token in tokens:\n",
        "      text.append(lemmatizer.lemmatize(token))\n",
        "    Documents.append(text)\n",
        "\n",
        "print(Documents)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFiZDpHRfft7",
        "outputId": "b69ad60b-0181-4882-95e5-51341fbdd886"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['Python', 'programming', 'language', 'build', 'website', 'software', 'automate', 'task', 'conduct', 'data', 'analysis'], ['Python', 'general', 'purpose', 'language', 'meaning', 'create', 'variety', 'different', 'program', 'specialized', 'specific', 'problem'], ['Python', 'extremely', 'popular', 'programming', 'language', 'officially', 'employed', 'primary', 'programming', 'language', 'great', 'majority', 'enterprise'], ['This', 'versatility', 'beginner', 'friendliness', 'most', 'used', 'programming', 'language', 'today'], ['A', 'survey', 'conducted', 'industry', 'analyst', 'firm', 'RedMonk', 'second', 'most', 'popular', 'programming', 'language', 'developer', '2021']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#finding Unique words\n",
        "Unique_word_set=np.union1d(Documents[0],Documents[1])\n",
        "Unique_word_set=np.union1d(Unique_word_set,Documents[2])\n",
        "Unique_word_set=np.union1d(Unique_word_set,Documents[3])\n",
        "wordset=np.union1d(Unique_word_set,Documents[4])\n",
        "\n",
        "print(wordset)"
      ],
      "metadata": {
        "id": "OyMPFfcP0BHJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45c03e71-d3a4-4a08-be16-d6615a302aaa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['2021' 'A' 'Python' 'RedMonk' 'This' 'analysis' 'analyst' 'automate'\n",
            " 'beginner' 'build' 'conduct' 'conducted' 'create' 'data' 'developer'\n",
            " 'different' 'employed' 'enterprise' 'extremely' 'firm' 'friendliness'\n",
            " 'general' 'great' 'industry' 'language' 'majority' 'meaning' 'most'\n",
            " 'officially' 'popular' 'primary' 'problem' 'program' 'programming'\n",
            " 'purpose' 'second' 'software' 'specialized' 'specific' 'survey' 'task'\n",
            " 'today' 'used' 'variety' 'versatility' 'website']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating Bag of words\n",
        "def calculateBOW(wordset,l_doc):\n",
        "  tf_diz = dict.fromkeys(wordset,0)\n",
        "  for word in l_doc:\n",
        "      tf_diz[word]=l_doc.count(word)\n",
        "  return tf_diz\n",
        "Bag_of_words=[]\n",
        "for doc in Documents:\n",
        "    Bag_of_words.append(calculateBOW(wordset,doc))"
      ],
      "metadata": {
        "id": "fE56kziMsRD2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Bag_of_words[4]"
      ],
      "metadata": {
        "id": "pmVuIm3d37C-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_bow = pd.DataFrame(Bag_of_words)\n",
        "BOW=df_bow.T\n",
        "BOW"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Q5hJOEWp39DF",
        "outputId": "e3fb8d33-23bc-4dd5-8fe2-b1ddd2341494"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              0  1  2  3  4\n",
              "2021          0  0  0  0  1\n",
              "A             0  0  0  0  1\n",
              "Python        1  1  1  0  0\n",
              "RedMonk       0  0  0  0  1\n",
              "This          0  0  0  1  0\n",
              "analysis      1  0  0  0  0\n",
              "analyst       0  0  0  0  1\n",
              "automate      1  0  0  0  0\n",
              "beginner      0  0  0  1  0\n",
              "build         1  0  0  0  0\n",
              "conduct       1  0  0  0  0\n",
              "conducted     0  0  0  0  1\n",
              "create        0  1  0  0  0\n",
              "data          1  0  0  0  0\n",
              "developer     0  0  0  0  1\n",
              "different     0  1  0  0  0\n",
              "employed      0  0  1  0  0\n",
              "enterprise    0  0  1  0  0\n",
              "extremely     0  0  1  0  0\n",
              "firm          0  0  0  0  1\n",
              "friendliness  0  0  0  1  0\n",
              "general       0  1  0  0  0\n",
              "great         0  0  1  0  0\n",
              "industry      0  0  0  0  1\n",
              "language      1  1  2  1  1\n",
              "majority      0  0  1  0  0\n",
              "meaning       0  1  0  0  0\n",
              "most          0  0  0  1  1\n",
              "officially    0  0  1  0  0\n",
              "popular       0  0  1  0  1\n",
              "primary       0  0  1  0  0\n",
              "problem       0  1  0  0  0\n",
              "program       0  1  0  0  0\n",
              "programming   1  0  2  1  1\n",
              "purpose       0  1  0  0  0\n",
              "second        0  0  0  0  1\n",
              "software      1  0  0  0  0\n",
              "specialized   0  1  0  0  0\n",
              "specific      0  1  0  0  0\n",
              "survey        0  0  0  0  1\n",
              "task          1  0  0  0  0\n",
              "today         0  0  0  1  0\n",
              "used          0  0  0  1  0\n",
              "variety       0  1  0  0  0\n",
              "versatility   0  0  0  1  0\n",
              "website       1  0  0  0  0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-767e8e17-14cb-4791-beb4-95a94674be99\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2021</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Python</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RedMonk</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>This</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>analysis</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>analyst</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>automate</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>beginner</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>build</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>conduct</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>conducted</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>create</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>data</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>developer</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>different</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>employed</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>enterprise</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>extremely</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>firm</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>friendliness</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>general</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>great</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>industry</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>language</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>majority</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>meaning</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>most</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>officially</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>popular</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>primary</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>problem</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>program</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>programming</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>purpose</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>second</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>software</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>specialized</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>specific</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>survey</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>task</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>today</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>used</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>variety</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>versatility</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>website</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-767e8e17-14cb-4791-beb4-95a94674be99')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-767e8e17-14cb-4791-beb4-95a94674be99 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-767e8e17-14cb-4791-beb4-95a94674be99');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Term frequency function\n",
        "def termFrequency(term, doc):\n",
        "        \n",
        "    # Splitting the document into individual terms\n",
        "    normalizeTermFreq = doc.lower().split()\n",
        " \n",
        "    # Number of times the term occurs in the document\n",
        "    term_in_document = normalizeTermFreq.count(term.lower())\n",
        " \n",
        "    # Total number of terms in the document\n",
        "    len_of_document = float(len(normalizeTermFreq ))\n",
        " \n",
        "    # Normalized Term Frequency\n",
        "    normalized_tf = term_in_document / len_of_document\n",
        " \n",
        "    return normalized_tf"
      ],
      "metadata": {
        "id": "wgvpn3Hf4Wt-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#termFrequency(\"RedMonk\",Doc5)"
      ],
      "metadata": {
        "id": "5l77sNdu40H4"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#finding Term frequency of each unique words\n",
        "def Termfreq_all(unique_words,AllDoc):\n",
        "  tf_word={}\n",
        "  \n",
        "  for token in unique_words:\n",
        "    tf_list_docwise=[]\n",
        "    for doc in AllDoc:\n",
        "      tf_list_docwise.append(termFrequency(token,doc))\n",
        "    \n",
        "    tf_word[token]=tf_list_docwise\n",
        "        \n",
        "  return tf_word\n"
      ],
      "metadata": {
        "id": "Nb2E__6y42ZW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Termfreq_all(wordset,AllDoc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KO9xe8q75KwG",
        "outputId": "f4d9f76f-20a1-4ba6-a980-fdca77890da4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'2021': [0.0, 0.0, 0.0, 0.0, 0.0], 'A': [0.05263157894736842, 0.08, 0.0, 0.0, 0.047619047619047616], 'Python': [0.05263157894736842, 0.04, 0.045454545454545456, 0.0, 0.0], 'RedMonk': [0.0, 0.0, 0.0, 0.0, 0.047619047619047616], 'This': [0.0, 0.0, 0.0, 0.0625, 0.0], 'analysis': [0.0, 0.0, 0.0, 0.0, 0.0], 'analyst': [0.0, 0.0, 0.0, 0.0, 0.047619047619047616], 'automate': [0.05263157894736842, 0.0, 0.0, 0.0, 0.0], 'beginner': [0.0, 0.0, 0.0, 0.0, 0.0], 'build': [0.05263157894736842, 0.0, 0.0, 0.0, 0.0], 'conduct': [0.05263157894736842, 0.0, 0.0, 0.0, 0.0], 'conducted': [0.0, 0.0, 0.0, 0.0, 0.047619047619047616], 'create': [0.0, 0.04, 0.0, 0.0, 0.0], 'data': [0.05263157894736842, 0.0, 0.0, 0.0, 0.0], 'developer': [0.0, 0.0, 0.0, 0.0, 0.0], 'different': [0.0, 0.04, 0.0, 0.0, 0.0], 'employed': [0.0, 0.0, 0.045454545454545456, 0.0, 0.0], 'enterprise': [0.0, 0.0, 0.0, 0.0, 0.0], 'extremely': [0.0, 0.0, 0.045454545454545456, 0.0, 0.0], 'firm': [0.0, 0.0, 0.0, 0.0, 0.047619047619047616], 'friendliness': [0.0, 0.0, 0.0, 0.0, 0.0], 'general': [0.0, 0.0, 0.0, 0.0, 0.0], 'great': [0.0, 0.0, 0.045454545454545456, 0.0, 0.0], 'industry': [0.0, 0.0, 0.0, 0.0, 0.047619047619047616], 'language': [0.05263157894736842, 0.0, 0.09090909090909091, 0.0, 0.047619047619047616], 'majority': [0.0, 0.0, 0.045454545454545456, 0.0, 0.0], 'meaning': [0.0, 0.04, 0.0, 0.0, 0.0], 'most': [0.0, 0.0, 0.0, 0.0, 0.0], 'officially': [0.0, 0.0, 0.045454545454545456, 0.0, 0.0], 'popular': [0.0, 0.0, 0.045454545454545456, 0.0, 0.047619047619047616], 'primary': [0.0, 0.0, 0.045454545454545456, 0.0, 0.0], 'problem': [0.0, 0.0, 0.0, 0.0, 0.0], 'program': [0.0, 0.0, 0.0, 0.0, 0.0], 'programming': [0.05263157894736842, 0.0, 0.09090909090909091, 0.0625, 0.047619047619047616], 'purpose': [0.0, 0.0, 0.0, 0.0, 0.0], 'second': [0.0, 0.0, 0.0, 0.0, 0.0], 'software': [0.0, 0.0, 0.0, 0.0, 0.0], 'specialized': [0.0, 0.04, 0.0, 0.0, 0.0], 'specific': [0.0, 0.04, 0.0, 0.0, 0.0], 'survey': [0.0, 0.0, 0.0, 0.0, 0.047619047619047616], 'task': [0.0, 0.0, 0.0, 0.0, 0.0], 'today': [0.0, 0.0, 0.0, 0.0, 0.0], 'used': [0.05263157894736842, 0.04, 0.0, 0.0, 0.0], 'variety': [0.0, 0.04, 0.0, 0.0, 0.0], 'versatility': [0.0, 0.0, 0.0, 0.0, 0.0], 'website': [0.0, 0.0, 0.0, 0.0, 0.0]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The Inverse Document Frequency -idf\n",
        "def IDF(corpus, unique_words):\n",
        "   idf_dict={}\n",
        "   N=len(corpus)\n",
        "   for i in unique_words:\n",
        "     count=0\n",
        "     for sen in corpus:\n",
        "       if i in sen.split():\n",
        "         count=count+1\n",
        "       idf_dict[i]=(math.log((1+N)/(count+1)))+1\n",
        "   return idf_dict "
      ],
      "metadata": {
        "id": "tLYrIqZ45Q2R"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idf=IDF(AllDoc,wordset)\n",
        "idf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1KBky115b8-",
        "outputId": "e1f8feef-64fb-4758-a224-ea12ee584208"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'2021': 2.791759469228055,\n",
              " 'A': 2.09861228866811,\n",
              " 'Python': 1.4054651081081644,\n",
              " 'RedMonk': 2.09861228866811,\n",
              " 'This': 2.09861228866811,\n",
              " 'analysis': 2.791759469228055,\n",
              " 'analyst': 2.09861228866811,\n",
              " 'automate': 2.09861228866811,\n",
              " 'beginner': 2.791759469228055,\n",
              " 'build': 2.09861228866811,\n",
              " 'conduct': 2.09861228866811,\n",
              " 'conducted': 2.09861228866811,\n",
              " 'create': 2.09861228866811,\n",
              " 'data': 2.09861228866811,\n",
              " 'developer': 2.791759469228055,\n",
              " 'different': 2.09861228866811,\n",
              " 'employed': 2.09861228866811,\n",
              " 'enterprise': 2.791759469228055,\n",
              " 'extremely': 2.09861228866811,\n",
              " 'firm': 2.09861228866811,\n",
              " 'friendliness': 2.791759469228055,\n",
              " 'general': 2.791759469228055,\n",
              " 'great': 2.09861228866811,\n",
              " 'industry': 2.09861228866811,\n",
              " 'language': 1.4054651081081644,\n",
              " 'majority': 2.09861228866811,\n",
              " 'meaning': 2.09861228866811,\n",
              " 'most': 2.791759469228055,\n",
              " 'officially': 2.09861228866811,\n",
              " 'popular': 1.6931471805599454,\n",
              " 'primary': 2.09861228866811,\n",
              " 'problem': 2.791759469228055,\n",
              " 'program': 2.791759469228055,\n",
              " 'programming': 1.1823215567939547,\n",
              " 'purpose': 2.791759469228055,\n",
              " 'second': 2.791759469228055,\n",
              " 'software': 2.791759469228055,\n",
              " 'specialized': 2.09861228866811,\n",
              " 'specific': 2.09861228866811,\n",
              " 'survey': 2.09861228866811,\n",
              " 'task': 2.791759469228055,\n",
              " 'today': 2.791759469228055,\n",
              " 'used': 1.6931471805599454,\n",
              " 'variety': 2.09861228866811,\n",
              " 'versatility': 2.791759469228055,\n",
              " 'website': 2.791759469228055}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TF-IDF score each term in a given document\n",
        "tf=termFrequency(\"Python\",Doc1)\n",
        "idf_term=idf[\"Python\"]\n",
        "Score=tf*idf_term\n",
        "\n",
        "#print(Score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pu6e_4J5eZ7",
        "outputId": "c7f5f58c-8da5-415a-bfe7-06966ea12d0e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.07397184779516654\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF Score wor all unique words \n",
        "def Score(unique_words,AllDoc):\n",
        "  idf=IDF(AllDoc,unique_words)\n",
        "  score={}\n",
        "  for token in unique_words:\n",
        "    Score=[]\n",
        "    for doc in AllDoc:\n",
        "      tf=termFrequency(token,doc)\n",
        "      Score.append(tf*idf[token])\n",
        "\n",
        "    score[token]=Score\n",
        "  return score\n",
        "Score(wordset,AllDoc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnCScIxF518x",
        "outputId": "3ba16c89-a3dd-44e4-f978-f4a061d882fa"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'2021': [0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " 'A': [0.11045327835095316, 0.1678889830934488, 0.0, 0.0, 0.09993391850800523],\n",
              " 'Python': [0.07397184779516654,\n",
              "  0.05621860432432658,\n",
              "  0.0638847776412802,\n",
              "  0.0,\n",
              "  0.0],\n",
              " 'RedMonk': [0.0, 0.0, 0.0, 0.0, 0.09993391850800523],\n",
              " 'This': [0.0, 0.0, 0.0, 0.13116326804175688, 0.0],\n",
              " 'analysis': [0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " 'analyst': [0.0, 0.0, 0.0, 0.0, 0.09993391850800523],\n",
              " 'automate': [0.11045327835095316, 0.0, 0.0, 0.0, 0.0],\n",
              " 'beginner': [0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " 'build': [0.11045327835095316, 0.0, 0.0, 0.0, 0.0],\n",
              " 'conduct': [0.11045327835095316, 0.0, 0.0, 0.0, 0.0],\n",
              " 'conducted': [0.0, 0.0, 0.0, 0.0, 0.09993391850800523],\n",
              " 'create': [0.0, 0.0839444915467244, 0.0, 0.0, 0.0],\n",
              " 'data': [0.11045327835095316, 0.0, 0.0, 0.0, 0.0],\n",
              " 'developer': [0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " 'different': [0.0, 0.0839444915467244, 0.0, 0.0, 0.0],\n",
              " 'employed': [0.0, 0.0, 0.09539146766673227, 0.0, 0.0],\n",
              " 'enterprise': [0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " 'extremely': [0.0, 0.0, 0.09539146766673227, 0.0, 0.0],\n",
              " 'firm': [0.0, 0.0, 0.0, 0.0, 0.09993391850800523],\n",
              " 'friendliness': [0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " 'general': [0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " 'great': [0.0, 0.0, 0.09539146766673227, 0.0, 0.0],\n",
              " 'industry': [0.0, 0.0, 0.0, 0.0, 0.09993391850800523],\n",
              " 'language': [0.07397184779516654,\n",
              "  0.0,\n",
              "  0.1277695552825604,\n",
              "  0.0,\n",
              "  0.06692690990991258],\n",
              " 'majority': [0.0, 0.0, 0.09539146766673227, 0.0, 0.0],\n",
              " 'meaning': [0.0, 0.0839444915467244, 0.0, 0.0, 0.0],\n",
              " 'most': [0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " 'officially': [0.0, 0.0, 0.09539146766673227, 0.0, 0.0],\n",
              " 'popular': [0.0, 0.0, 0.07696123547999752, 0.0, 0.08062605621714025],\n",
              " 'primary': [0.0, 0.0, 0.09539146766673227, 0.0, 0.0],\n",
              " 'problem': [0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " 'program': [0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " 'programming': [0.062227450357576555,\n",
              "  0.0,\n",
              "  0.10748377789035952,\n",
              "  0.07389509729962217,\n",
              "  0.05630102651399784],\n",
              " 'purpose': [0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " 'second': [0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " 'software': [0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " 'specialized': [0.0, 0.0839444915467244, 0.0, 0.0, 0.0],\n",
              " 'specific': [0.0, 0.0839444915467244, 0.0, 0.0, 0.0],\n",
              " 'survey': [0.0, 0.0, 0.0, 0.0, 0.09993391850800523],\n",
              " 'task': [0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " 'today': [0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " 'used': [0.08911300950315501, 0.06772588722239782, 0.0, 0.0, 0.0],\n",
              " 'variety': [0.0, 0.0839444915467244, 0.0, 0.0, 0.0],\n",
              " 'versatility': [0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " 'website': [0.0, 0.0, 0.0, 0.0, 0.0]}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "yXaxPx4h6Fpm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}